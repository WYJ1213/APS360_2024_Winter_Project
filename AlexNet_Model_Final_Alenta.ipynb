{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Libraries**"
      ],
      "metadata": {
        "id": "-IttN-qB8sa0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKpdgnOR8j-s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
        "import pickle\n",
        "import seaborn as sns\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "Categories=['trash','recycle','organics', 'hazardous']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Data**"
      ],
      "metadata": {
        "id": "gXVjCtCxFf4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIcTlm3s8xeP",
        "outputId": "4951101b-c15c-4f49-a903-f179caeacd44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir=\"/content/drive/MyDrive/APS360/APS360 Project/APS360 Process Report Dataset/train\"\n",
        "val_dir=\"/content/drive/MyDrive/APS360/APS360 Project/APS360 Process Report Dataset/val\"\n",
        "test_dir=\"/content/drive/MyDrive/APS360/APS360 Project/APS360 Process Report Dataset/test\""
      ],
      "metadata": {
        "id": "FuNts7Z489fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_train_dir=\"/content/drive/MyDrive/APS360/APS360 Project/Process Report Small Dataset/train\"\n",
        "small_val_dir=\"/content/drive/MyDrive/APS360/APS360 Project/Process Report Small Dataset/val\""
      ],
      "metadata": {
        "id": "Z74ygZQSVAJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1)\n",
        "\n",
        "# Apply transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),            # Resize to 256x256 pixels\n",
        "    transforms.CenterCrop(224),        # Crop to 224x224 pixels\n",
        "    # 224: standard input size for AlexNet, VGG, and ResNet\n",
        "    # images to tensors: normalizes pixel values and allows for mathematical operations within NN\n",
        "    transforms.ToTensor(),             # Convert images to tensors\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet mean and standard deviation\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
        "val_dataset = datasets.ImageFolder(val_dir, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "# Set up data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "validation_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "## For small dataset\n",
        "small_train_dataset = datasets.ImageFolder(small_train_dir, transform=transform)\n",
        "small_val_dataset = datasets.ImageFolder(small_val_dir, transform=transform)\n",
        "\n",
        "# Set up data loaders\n",
        "small_train_loader = DataLoader(small_train_dataset, batch_size=32, shuffle=True)\n",
        "small_validation_loader = DataLoader(small_val_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "HDKh-8pWFimq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T**rain model on AlexNet**"
      ],
      "metadata": {
        "id": "zbHvmWf2JPeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alexnet = models.alexnet(pretrained=True)\n",
        "alexnet.classifier[6] = torch.nn.Linear(alexnet.classifier[6].in_features, 4)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "alexnet = alexnet.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDcc0kb9JPK0",
        "outputId": "742a1e57-7cd3-4b78-d982-c02c1c7a69f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:02<00:00, 85.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Create the model\n",
        "alexnet2 = AlexNet(num_classes=4)"
      ],
      "metadata": {
        "id": "ut2gkDNfvV8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_net(model, train_loader, val_loader, batch_size=32,\n",
        "              lr=0.001, num_epochs=15):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)  # Using Adam optimizer\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "        running_loss = 0.0\n",
        "        train_preds = []\n",
        "        train_targets = []\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_preds.extend(predicted.cpu().numpy())\n",
        "            train_targets.extend(labels.cpu().numpy())\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = accuracy_score(train_targets, train_preds)\n",
        "        epoch_f1 = f1_score(train_targets, train_preds, average='weighted')\n",
        "\n",
        "        model.eval()  # Set model to evaluate mode\n",
        "        val_running_loss = 0.0\n",
        "        val_preds = []\n",
        "        val_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_running_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_preds.extend(predicted.cpu().numpy())\n",
        "                val_targets.extend(labels.cpu().numpy())\n",
        "\n",
        "        val_loss = val_running_loss / len(val_loader.dataset)\n",
        "        val_acc = accuracy_score(val_targets, val_preds)\n",
        "        val_f1 = f1_score(val_targets, val_preds, average='weighted')\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print(f'Training Accuracy: {epoch_acc:.4f}, F1-Score: {epoch_f1:.4f}, Loss: {epoch_loss:.4f}')\n",
        "        print(f'Validation Accuracy: {val_acc:.4f}, F1-Score: {val_f1:.4f}, Loss: {val_loss:.4f}, ')\n"
      ],
      "metadata": {
        "id": "6lFp7aFSrmdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train on small dataset"
      ],
      "metadata": {
        "id": "Bn_4oWaaZyd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_net(alexnet2, small_train_loader, small_validation_loader, batch_size=64,\n",
        "              lr=0.0001, num_epochs=30)\n",
        "'''we see that the training accuracy and f1-score is converging to 1.\n",
        "but the model struggle with new or unseen data, since validation\n",
        "metrics are not performing well.'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA3fGyDfvsoG",
        "outputId": "8c539b8e-b131-4bb6-a725-87cab41fc7b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "Training Accuracy: 0.4167, F1-Score: 0.3654, Loss: 1.2542\n",
            "Validation Accuracy: 0.2500, F1-Score: 0.1623, Loss: 1.3278, \n",
            "Epoch 2/30\n",
            "Training Accuracy: 0.4167, F1-Score: 0.3464, Loss: 1.2389\n",
            "Validation Accuracy: 0.4167, F1-Score: 0.2778, Loss: 1.3166, \n",
            "Epoch 3/30\n",
            "Training Accuracy: 0.5000, F1-Score: 0.4179, Loss: 1.1993\n",
            "Validation Accuracy: 0.4167, F1-Score: 0.2917, Loss: 1.3070, \n",
            "Epoch 4/30\n",
            "Training Accuracy: 0.3333, F1-Score: 0.2222, Loss: 1.2173\n",
            "Validation Accuracy: 0.4167, F1-Score: 0.2917, Loss: 1.2980, \n",
            "Epoch 5/30\n",
            "Training Accuracy: 0.5000, F1-Score: 0.4179, Loss: 1.1527\n",
            "Validation Accuracy: 0.4167, F1-Score: 0.2917, Loss: 1.2920, \n",
            "Epoch 6/30\n",
            "Training Accuracy: 0.4167, F1-Score: 0.3631, Loss: 1.2324\n",
            "Validation Accuracy: 0.3333, F1-Score: 0.2381, Loss: 1.2845, \n",
            "Epoch 7/30\n",
            "Training Accuracy: 0.5833, F1-Score: 0.5667, Loss: 1.1770\n",
            "Validation Accuracy: 0.2500, F1-Score: 0.1667, Loss: 1.2754, \n",
            "Epoch 8/30\n",
            "Training Accuracy: 0.5833, F1-Score: 0.5000, Loss: 1.0717\n",
            "Validation Accuracy: 0.2500, F1-Score: 0.1667, Loss: 1.2706, \n",
            "Epoch 9/30\n",
            "Training Accuracy: 0.5833, F1-Score: 0.5583, Loss: 0.9264\n",
            "Validation Accuracy: 0.0833, F1-Score: 0.0714, Loss: 1.2773, \n",
            "Epoch 10/30\n",
            "Training Accuracy: 0.6667, F1-Score: 0.6917, Loss: 1.0145\n",
            "Validation Accuracy: 0.1667, F1-Score: 0.1429, Loss: 1.3031, \n",
            "Epoch 11/30\n",
            "Training Accuracy: 0.7500, F1-Score: 0.7292, Loss: 0.8861\n",
            "Validation Accuracy: 0.1667, F1-Score: 0.1429, Loss: 1.3644, \n",
            "Epoch 12/30\n",
            "Training Accuracy: 0.7500, F1-Score: 0.7202, Loss: 0.7818\n",
            "Validation Accuracy: 0.2500, F1-Score: 0.2262, Loss: 1.4853, \n",
            "Epoch 13/30\n",
            "Training Accuracy: 0.5833, F1-Score: 0.5833, Loss: 0.9245\n",
            "Validation Accuracy: 0.3333, F1-Score: 0.2944, Loss: 1.6991, \n",
            "Epoch 14/30\n",
            "Training Accuracy: 0.7500, F1-Score: 0.7542, Loss: 0.6830\n",
            "Validation Accuracy: 0.3333, F1-Score: 0.2944, Loss: 2.0416, \n",
            "Epoch 15/30\n",
            "Training Accuracy: 0.7500, F1-Score: 0.7542, Loss: 0.7280\n",
            "Validation Accuracy: 0.3333, F1-Score: 0.2992, Loss: 2.4848, \n",
            "Epoch 16/30\n",
            "Training Accuracy: 0.6667, F1-Score: 0.6542, Loss: 0.6434\n",
            "Validation Accuracy: 0.3333, F1-Score: 0.2992, Loss: 2.7732, \n",
            "Epoch 17/30\n",
            "Training Accuracy: 0.6667, F1-Score: 0.6542, Loss: 0.6582\n",
            "Validation Accuracy: 0.3333, F1-Score: 0.2944, Loss: 2.7431, \n",
            "Epoch 18/30\n",
            "Training Accuracy: 0.8333, F1-Score: 0.8375, Loss: 0.5281\n",
            "Validation Accuracy: 0.3333, F1-Score: 0.2944, Loss: 2.7870, \n",
            "Epoch 19/30\n",
            "Training Accuracy: 0.8333, F1-Score: 0.8310, Loss: 0.4598\n",
            "Validation Accuracy: 0.3333, F1-Score: 0.2944, Loss: 2.6977, \n",
            "Epoch 20/30\n",
            "Training Accuracy: 0.8333, F1-Score: 0.8310, Loss: 0.4054\n",
            "Validation Accuracy: 0.3333, F1-Score: 0.2944, Loss: 2.7290, \n",
            "Epoch 21/30\n",
            "Training Accuracy: 0.8333, F1-Score: 0.8375, Loss: 0.4998\n",
            "Validation Accuracy: 0.4167, F1-Score: 0.4111, Loss: 2.8415, \n",
            "Epoch 22/30\n",
            "Training Accuracy: 0.8333, F1-Score: 0.8310, Loss: 0.4329\n",
            "Validation Accuracy: 0.4167, F1-Score: 0.4194, Loss: 2.9681, \n",
            "Epoch 23/30\n",
            "Training Accuracy: 0.8333, F1-Score: 0.8310, Loss: 0.5774\n",
            "Validation Accuracy: 0.4167, F1-Score: 0.4194, Loss: 3.0708, \n",
            "Epoch 24/30\n",
            "Training Accuracy: 0.9167, F1-Score: 0.9143, Loss: 0.3064\n",
            "Validation Accuracy: 0.4167, F1-Score: 0.4194, Loss: 3.2651, \n",
            "Epoch 25/30\n",
            "Training Accuracy: 0.9167, F1-Score: 0.9143, Loss: 0.2953\n",
            "Validation Accuracy: 0.4167, F1-Score: 0.4194, Loss: 3.5447, \n",
            "Epoch 26/30\n",
            "Training Accuracy: 0.9167, F1-Score: 0.9143, Loss: 0.3687\n",
            "Validation Accuracy: 0.4167, F1-Score: 0.4194, Loss: 3.9507, \n",
            "Epoch 27/30\n",
            "Training Accuracy: 0.9167, F1-Score: 0.9143, Loss: 0.2594\n",
            "Validation Accuracy: 0.4167, F1-Score: 0.4194, Loss: 4.3742, \n",
            "Epoch 28/30\n",
            "Training Accuracy: 0.9167, F1-Score: 0.9143, Loss: 0.2202\n",
            "Validation Accuracy: 0.4167, F1-Score: 0.4333, Loss: 4.9438, \n",
            "Epoch 29/30\n",
            "Training Accuracy: 0.9167, F1-Score: 0.9143, Loss: 0.2140\n",
            "Validation Accuracy: 0.4167, F1-Score: 0.4194, Loss: 5.0876, \n",
            "Epoch 30/30\n",
            "Training Accuracy: 0.9167, F1-Score: 0.9143, Loss: 0.2146\n",
            "Validation Accuracy: 0.4167, F1-Score: 0.4194, Loss: 5.1395, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train on original dataset"
      ],
      "metadata": {
        "id": "YLilz7K3aWaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''these are the paramters that our team agreed on\n",
        "for our progress report\n",
        "Result:\n",
        "Epoch 15/15\n",
        "Training Accuracy: 0.6017, F1-Score: 0.5946, Loss: 0.9645\n",
        "Validation Accuracy: 0.5700, F1-Score: 0.5417, Loss: 1.0353'''\n",
        "train_net(alexnet2, train_loader, validation_loader, batch_size=32,\n",
        "              lr=0.001, num_epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va02NirN1Ex2",
        "outputId": "fee2d04d-dabf-4a59-a9d6-78bb6037ea67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "Training Accuracy: 0.3100, F1-Score: 0.2564, Loss: 1.6180\n",
            "Validation Accuracy: 0.3200, F1-Score: 0.2684, Loss: 1.3583, \n",
            "Epoch 2/15\n",
            "Training Accuracy: 0.3983, F1-Score: 0.3881, Loss: 1.2581\n",
            "Validation Accuracy: 0.3350, F1-Score: 0.3173, Loss: 1.2847, \n",
            "Epoch 3/15\n",
            "Training Accuracy: 0.5067, F1-Score: 0.5071, Loss: 1.1037\n",
            "Validation Accuracy: 0.4400, F1-Score: 0.3661, Loss: 1.2238, \n",
            "Epoch 4/15\n",
            "Training Accuracy: 0.4700, F1-Score: 0.4253, Loss: 1.3525\n",
            "Validation Accuracy: 0.4250, F1-Score: 0.3607, Loss: 1.2961, \n",
            "Epoch 5/15\n",
            "Training Accuracy: 0.4450, F1-Score: 0.4333, Loss: 1.1689\n",
            "Validation Accuracy: 0.2900, F1-Score: 0.1730, Loss: 1.5422, \n",
            "Epoch 6/15\n",
            "Training Accuracy: 0.4200, F1-Score: 0.4151, Loss: 1.2498\n",
            "Validation Accuracy: 0.3750, F1-Score: 0.3775, Loss: 1.2588, \n",
            "Epoch 7/15\n",
            "Training Accuracy: 0.5183, F1-Score: 0.4957, Loss: 1.0989\n",
            "Validation Accuracy: 0.3950, F1-Score: 0.3406, Loss: 1.1958, \n",
            "Epoch 8/15\n",
            "Training Accuracy: 0.5000, F1-Score: 0.4939, Loss: 1.0657\n",
            "Validation Accuracy: 0.4550, F1-Score: 0.3950, Loss: 1.1838, \n",
            "Epoch 9/15\n",
            "Training Accuracy: 0.5333, F1-Score: 0.4699, Loss: 1.0129\n",
            "Validation Accuracy: 0.4450, F1-Score: 0.3835, Loss: 1.1691, \n",
            "Epoch 10/15\n",
            "Training Accuracy: 0.5667, F1-Score: 0.5274, Loss: 0.9578\n",
            "Validation Accuracy: 0.5100, F1-Score: 0.5094, Loss: 1.1105, \n",
            "Epoch 11/15\n",
            "Training Accuracy: 0.5950, F1-Score: 0.5941, Loss: 0.9461\n",
            "Validation Accuracy: 0.5100, F1-Score: 0.5061, Loss: 1.0967, \n",
            "Epoch 12/15\n",
            "Training Accuracy: 0.6967, F1-Score: 0.6958, Loss: 0.8421\n",
            "Validation Accuracy: 0.5700, F1-Score: 0.5444, Loss: 1.1196, \n",
            "Epoch 13/15\n",
            "Training Accuracy: 0.6150, F1-Score: 0.6149, Loss: 0.9978\n",
            "Validation Accuracy: 0.5600, F1-Score: 0.5459, Loss: 1.0691, \n",
            "Epoch 14/15\n",
            "Training Accuracy: 0.6300, F1-Score: 0.6260, Loss: 0.9517\n",
            "Validation Accuracy: 0.4950, F1-Score: 0.4324, Loss: 1.1570, \n",
            "Epoch 15/15\n",
            "Training Accuracy: 0.6017, F1-Score: 0.5946, Loss: 0.9645\n",
            "Validation Accuracy: 0.5700, F1-Score: 0.5417, Loss: 1.0353, \n"
          ]
        }
      ]
    }
  ]
}