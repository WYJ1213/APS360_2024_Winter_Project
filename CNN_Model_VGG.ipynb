{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkZXIVd-UvxX"
      },
      "source": [
        "##**Package loading**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNEaijkuU0-B"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mCA0PXQU4uG"
      },
      "source": [
        "##**Mount to Drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjexttTsU3RR",
        "outputId": "be34083c-6afa-493e-e3bf-6fddb7f22985"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiKB5G13ZgRb"
      },
      "outputs": [],
      "source": [
        "train_dir=\"/content/drive/MyDrive/University/U_Third/Winter term/APS360/APS360 Project/APS360 Process Report Dataset/train\"\n",
        "val_dir=\"/content/drive/MyDrive/University/U_Third/Winter term/APS360/APS360 Project/APS360 Process Report Dataset/val\"\n",
        "test_dir=\"/content/drive/MyDrive/University/U_Third/Winter term/APS360/APS360 Project/APS360 Process Report Dataset/test\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlSav0BrajJO"
      },
      "source": [
        "##**Load the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87NFevVfcVCG"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "# Define transformations and normalization for your images:\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images for the VGG model\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Standard normalization for ImageNet\n",
        "])\n",
        "\n",
        "# Load datasets:\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
        "val_dataset = datasets.ImageFolder(val_dir, transform=transform)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "# Set up data loaders:\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)  #Shuffle is to ensure the model isnâ€™t adapting its learning to any kind of spurious pattern.\n",
        "validation_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXMcq4ecFg9Z"
      },
      "source": [
        "##**Check the labels of the train dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Aklk7QiFkKU",
        "outputId": "29560d6a-f512-40e9-a02d-a5b1086d339d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels for one batch: tensor([1, 3, 1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 0, 1, 0, 1, 0, 1, 3, 3, 0, 1, 0, 1,\n",
            "        2, 0, 0, 2, 2, 3, 3, 3])\n",
            "Class names for one batch: ['organics', 'trash', 'organics', 'organics', 'recycle', 'hazardous', 'recycle', 'hazardous', 'trash', 'recycle', 'hazardous', 'recycle', 'hazardous', 'organics', 'hazardous', 'organics', 'hazardous', 'organics', 'trash', 'trash', 'hazardous', 'organics', 'hazardous', 'organics', 'recycle', 'hazardous', 'hazardous', 'recycle', 'recycle', 'trash', 'trash', 'trash']\n"
          ]
        }
      ],
      "source": [
        "# Check labels for one batch of the training data\n",
        "for images, labels in train_loader:\n",
        "    print(\"Labels for one batch:\", labels)\n",
        "    print(\"Class names for one batch:\", [list(train_dataset.class_to_idx.keys())[list(train_dataset.class_to_idx.values()).index(label)] for label in labels])\n",
        "    break  # Only look at the first batch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRC3ciYRsnDC"
      },
      "source": [
        "##**Check labels for the validation data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CTvdl41snOx",
        "outputId": "0bce78b3-2ae2-44d0-c4a1-64816fa79906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels for one batch: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Class names for one batch: ['hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous']\n",
            "Labels for one batch: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Class names for one batch: ['hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous']\n",
            "Labels for one batch: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Class names for one batch: ['hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous', 'hazardous']\n"
          ]
        }
      ],
      "source": [
        "i=0\n",
        "for images, labels in validation_loader:\n",
        "    while(i<3):\n",
        "     print(\"Labels for one batch:\", labels)\n",
        "     print(\"Class names for one batch:\", [list(val_dataset.class_to_idx.keys())[list(val_dataset.class_to_idx.values()).index(label)] for label in labels])\n",
        "     i+=1 # Only look at the first batch\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acH_TPc4d5XE"
      },
      "source": [
        "##**Buildup the arichitecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaygOODLc4WG",
        "outputId": "b5b4a79d-1804-4c49-a446-24fee1f3d29a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG16(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=4):  # Categories=['trash','recycle','organics', 'hazardous']\n",
        "        super(VGG16, self).__init__()\n",
        "        self.name= \"VGG16\"\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Block 2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Block 3\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Block 4\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Block 5\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "vgg16 = VGG16(num_classes=4)  # four classes\n",
        "\n",
        "# Print the model architecture\n",
        "print(vgg16)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS7iMVbFfREN"
      },
      "source": [
        "##**Set up the loss function and  Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjVDmY13fVgm",
        "outputId": "3a4c8bc4-7c12-411f-f325-b31040a9d704"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VGG16(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# For multi-class classification\n",
        "optimizer = optim.Adam(vgg16.parameters(), lr=0.001)  # Use Adam optimizer with a learning rate of 0.01\n",
        "\n",
        "#device should be defined based on system's configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vgg16.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vfcXiB4grWJ"
      },
      "source": [
        "##**Train the model and get the training test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dj4xqb5Hgtx3",
        "outputId": "fbe45656-2232-49b2-f325-f1a178779ebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15], Training Accuracy: 25.5%\n",
            "Validation Accuracy: 25.0%\n",
            "Epoch [2/15], Training Accuracy: 23.333333333333332%\n",
            "Validation Accuracy: 25.0%\n",
            "Epoch [3/15], Training Accuracy: 24.5%\n",
            "Validation Accuracy: 25.0%\n",
            "Epoch [4/15], Training Accuracy: 24.166666666666668%\n",
            "Validation Accuracy: 25.0%\n",
            "Epoch [5/15], Training Accuracy: 24.833333333333332%\n",
            "Validation Accuracy: 25.0%\n",
            "Epoch [6/15], Training Accuracy: 29.5%\n",
            "Validation Accuracy: 36.0%\n",
            "Epoch [7/15], Training Accuracy: 39.0%\n",
            "Validation Accuracy: 38.5%\n",
            "Epoch [8/15], Training Accuracy: 49.666666666666664%\n",
            "Validation Accuracy: 40.0%\n",
            "Epoch [9/15], Training Accuracy: 55.833333333333336%\n",
            "Validation Accuracy: 52.0%\n",
            "Epoch [10/15], Training Accuracy: 65.66666666666667%\n",
            "Validation Accuracy: 58.0%\n",
            "Epoch [11/15], Training Accuracy: 69.16666666666667%\n",
            "Validation Accuracy: 52.5%\n",
            "Epoch [12/15], Training Accuracy: 71.66666666666667%\n",
            "Validation Accuracy: 54.5%\n",
            "Epoch [13/15], Training Accuracy: 75.0%\n",
            "Validation Accuracy: 58.5%\n",
            "Epoch [14/15], Training Accuracy: 77.33333333333333%\n",
            "Validation Accuracy: 59.0%\n",
            "Epoch [15/15], Training Accuracy: 81.16666666666667%\n",
            "Validation Accuracy: 63.0%\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 15  # Set the number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    vgg16.train()  # Set the vgg16 to training mode\n",
        "    total_train = 0\n",
        "    correct_train = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # Transfer to GPU if available\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the parameter gradients\n",
        "\n",
        "        outputs = vgg16(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate training accuracy\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Training Accuracy: {train_accuracy}%')\n",
        "\n",
        "    vgg16.eval()  # Set the vgg16 to evaluation mode\n",
        "    total_val = 0\n",
        "    correct_val = 0\n",
        "    with torch.no_grad():  # No need to track gradients for validation\n",
        "        for inputs, labels in validation_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # Transfer to GPU if available\n",
        "\n",
        "            outputs = vgg16(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "        val_accuracy = 100 * correct_val / total_val\n",
        "        print(f'Validation Accuracy: {val_accuracy}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Tuning in next stage**"
      ],
      "metadata": {
        "id": "kzilDhmudCJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_loader, validation_loader,num_epochs, learning_rate, batch_size=None):\n",
        "    # Instantiate the model\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(vgg16.parameters(), lr=learning_rate)  # Use Adam optimizer with the learning rate parameter\n",
        "\n",
        "    # device should be defined based on system's configuration\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    vgg16.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):  # Use the num_epochs parameter\n",
        "      vgg16.train()  # Set the vgg16 to training mode\n",
        "      total_train = 0\n",
        "      correct_train = 0\n",
        "\n",
        "      for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # Transfer to GPU if available\n",
        "            optimizer.zero_grad()  # Zero the parameter gradients\n",
        "\n",
        "            outputs =vgg16(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "      # Calculate training accuracy\n",
        "      train_accuracy = 100 * correct_train / total_train\n",
        "      print(f'Epoch [{epoch + 1}/{num_epochs}], Training Accuracy: {train_accuracy}%')\n",
        "\n",
        "      vgg16.eval()  # Set the vgg16 to evaluation mode\n",
        "      total_val = 0\n",
        "      correct_val = 0\n",
        "      with torch.no_grad():  # No need to track gradients for validation\n",
        "        for inputs, labels in validation_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)  # Transfer to GPU if available\n",
        "                outputs =vgg16(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total_val += labels.size(0)\n",
        "                correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "        val_accuracy = 100 * correct_val / total_val\n",
        "        print(f'Validation Accuracy: {val_accuracy}%')\n"
      ],
      "metadata": {
        "id": "O-99Gs7NdFZ5"
      },
      "execution_count": 29,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}